import os
import json
import requests
import wbdata
import datetime
import zipfile
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
import signal

# ---------------------------
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
# ---------------------------
OUTPUT_FILE = os.path.join("public", "data", "cities.json")
GEONAMES_URL = "http://download.geonames.org/export/dump/cities15000.zip"
GEONAMES_FILE = "cities15000.txt"
TOP_N = 2000
BATCH_SIZE = 100
MAX_WORKERS = 15

stop_flag = False

# ---------------------------
# Ctrl+C
# ---------------------------
def signal_handler(sig, frame):
    global stop_flag
    print("\n‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å...")
    stop_flag = True

signal.signal(signal.SIGINT, signal_handler)

# ---------------------------
# GeoNames
# ---------------------------
def download_geonames():
    if not os.path.exists(GEONAMES_FILE):
        print("üì• –°–∫–∞—á–∏–≤–∞–µ–º GeoNames...")
        r = requests.get(GEONAMES_URL)
        with open("cities.zip", "wb") as f:
            f.write(r.content)
        with zipfile.ZipFile("cities.zip", "r") as zip_ref:
            zip_ref.extractall(".")
    else:
        print("‚úÖ GeoNames —É–∂–µ —Å–∫–∞—á–∞–Ω")

def load_top_cities(limit=TOP_N):
    cities = []
    with open(GEONAMES_FILE, "r", encoding="utf-8") as f:
        for line in f:
            parts = line.strip().split("\t")
            if len(parts) < 15:
                continue
            try:
                population = int(parts[14])
            except ValueError:
                population = 0
            city = {
                "geonameid": int(parts[0]),
                "name": parts[1],
                "country": parts[8],
                "lat": float(parts[4]),
                "lon": float(parts[5]),
                "population": population
            }
            cities.append(city)
    cities.sort(key=lambda x: x["population"], reverse=True)
    return cities[:limit]

# ---------------------------
# World Bank (–ø–æ —Å—Ç—Ä–∞–Ω–µ)
# ---------------------------
def get_worldbank_country_data(country_code):
    indicators = {
        "gdp_per_capita": "NY.GDP.PCAP.CD",
        "unemployment_rate": "SL.UEM.TOTL.ZS",
        "inflation_rate": "FP.CPI.TOTL.ZG",
        "life_expectancy": "SP.DYN.LE00.IN",
        "infant_mortality_rate": "SP.DYN.IMRT.IN",
        "co2_emissions_per_capita": "EN.ATM.CO2E.PC",
        "literacy_rate": "SE.ADT.LITR.ZS",
        "tertiary_education_enrollment": "SE.TER.ENRR"
    }
    data = {}
    try:
        for field, code in indicators.items():
            df = wbdata.get_dataframe({code: field}, country=country_code)
            if not df.empty:
                val = df[field].dropna().iloc[-1]
                data[field] = float(val)
    except Exception:
        pass
    return data

# ---------------------------
# WHO (–ø–æ —Å—Ç—Ä–∞–Ω–µ)
# ---------------------------
def get_who_country_data(country_code):
    endpoints = {
        "doctors_per_1000": "HWF_0001",
        "hospital_beds_per_1000": "HOSP_BEDS"
    }
    data = {}
    for field, code in endpoints.items():
        url = f"https://ghoapi.azureedge.net/api/{code}?$filter=SpatialDim eq '{country_code}'"
        try:
            r = requests.get(url, timeout=10)
            if r.status_code == 200:
                js = r.json()
                values = [v.get("NumericValue") for v in js.get("value", []) if v.get("NumericValue") is not None]
                if values:
                    data[field] = float(values[-1])
        except Exception:
            continue
    return data

# ---------------------------
# UNODC (–ø–æ —Å—Ç—Ä–∞–Ω–µ)
# ---------------------------
def load_unodc_data():
    url = "https://dataunodc.un.org/content/data/Crime_by_country.csv"
    try:
        df = pd.read_csv(url)
        df = df.rename(columns={
            "Country": "country_name",
            "Homicide Rate": "homicide_rate",
            "Theft Rate": "theft_rate"
        })
        df = df[["country_name", "homicide_rate", "theft_rate"]]
        return df.set_index("country_name").to_dict(orient="index")
    except Exception:
        return {}

# ---------------------------
# OpenAQ (–ø–æ –≥–æ—Ä–æ–¥—É)
# ---------------------------
def get_openaq(city_name):
    url = f"https://api.openaq.org/v2/latest?city={city_name}"
    try:
        r = requests.get(url, timeout=10)
        if r.status_code != 200:
            return {}
        data = r.json()
        pm25, no2 = None, None
        if "results" in data and len(data["results"]) > 0:
            for m in data["results"][0].get("measurements", []):
                if m["parameter"] == "pm25":
                    pm25 = m["value"]
                if m["parameter"] == "no2":
                    no2 = m["value"]
        return {"pm25": pm25, "no2": no2}
    except Exception:
        return {}

# ---------------------------
# –ö–ª–∏–º–∞—Ç
# ---------------------------
def get_climate(lat, lon):
    try:
        url = f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&daily=temperature_2m_max,precipitation_sum&timezone=GMT"
        r = requests.get(url, timeout=10)
        if r.status_code == 200:
            js = r.json()
            temps = js.get("daily", {}).get("temperature_2m_max", [])
            precs = js.get("daily", {}).get("precipitation_sum", [])
            return {
                "avg_temperature": round(sum(temps)/len(temps), 2) if temps else None,
                "avg_precipitation": round(sum(precs), 2) if precs else None
            }
    except Exception:
        pass
    return {"avg_temperature": None, "avg_precipitation": None}

# ---------------------------
# –¢—Ä–∞—Ñ–∏–∫ (TomTom Traffic Index, –æ—Ç–∫—Ä—ã—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ)
# ---------------------------
def get_transport_index(city_name):
    # –û—Ç–∫—Ä—ã—Ç—ã–µ —Ä–µ–π—Ç–∏–Ω–≥–∏ TomTom 2023 –¥–ª—è –∫—Ä—É–ø–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤ (–ø—Ä–∏–º–µ—Ä)
    traffic_dict = {
        "Berlin": 38.2,
        "Prague": 30.5,
        "New York": 46.0,
        "Los Angeles": 47.5,
        "London": 39.1,
        "Paris": 35.0,
        "Tokyo": 28.5,
        "Beijing": 33.0,
        "Shanghai": 32.5
        # –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≥–æ—Ä–æ–¥–∞ = null
    }
    return {"traffic_congestion_index": traffic_dict.get(city_name)}

# ---------------------------
# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –≥–æ—Ä–æ–¥–∞
# ---------------------------
def process_city(city, wb_data, who_data, crime_data):
    if stop_flag:
        return None
    print(f"üîπ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {city['name']} ({city['geonameid']})")
    record = {
        "geonameid": city["geonameid"],
        "name": city["name"],
        "country": city["country"],
        "lat": city["lat"],
        "lon": city["lon"],
        "population": city["population"]
    }
    record.update(wb_data.get(city["country"], {}))
    record.update(who_data.get(city["country"], {}))
    cname = city.get("country_name") or city.get("country")
    if cname in crime_data:
        record.update(crime_data[cname])
    record.update(get_openaq(city["name"]))
    record.update(get_climate(city["lat"], city["lon"]))
    transport = get_transport_index(city["name"])
    if transport:
        record.update(transport)
    return record

# ---------------------------
# –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å
# ---------------------------
def main():
    download_geonames()
    cities = load_top_cities(TOP_N)
    print(f"üåç –í—Å–µ–≥–æ –≥–æ—Ä–æ–¥–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(cities)}")

    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π JSON
    if os.path.exists(OUTPUT_FILE):
        os.remove(OUTPUT_FILE)
        print(f"üóë –°—Ç–∞—Ä—ã–π —Ñ–∞–π–ª {OUTPUT_FILE} —É–¥–∞–ª—ë–Ω")

    countries = set([c["country"] for c in cities])
    wb_data = {c: get_worldbank_country_data(c) for c in countries}
    who_data = {c: get_who_country_data(c) for c in countries}
    crime_data = load_unodc_data()

    results = []

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_city = {executor.submit(process_city, city, wb_data, who_data, crime_data): city for city in cities}
        for i, future in enumerate(as_completed(future_to_city), 1):
            if stop_flag:
                break
            city_record = future.result()
            if city_record:
                results.append(city_record)
            if i % BATCH_SIZE == 0:
                with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(results)} –≥–æ—Ä–æ–¥–æ–≤...")

    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(results)} –≥–æ—Ä–æ–¥–æ–≤, —Ñ–∞–π–ª: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
